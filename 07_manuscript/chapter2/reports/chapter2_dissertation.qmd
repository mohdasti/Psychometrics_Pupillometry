---
title: "Pupil-Indexed Arousal and Psychometric Sensitivity in Older Adults"
author: "Mohammad Dastgheib"
bibliography: references.bib
csl: apa-7th-edition.csl
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    embed-resources: true
  pdf:
    toc: true
    toc-depth: 3
    number-sections: true
    documentclass: article
    geometry:
      - margin=1in
    fontsize: 11pt
    linestretch: 1.5
    fig-pos: "H"
  docx:
    toc: true
    number-sections: true

execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
#| include: false

library(dplyr)
library(readr)
library(tidyr)
library(gt)
library(glue)
library(stringr)
library(knitr)
library(ggplot2)
library(kableExtra)
library(here)

# Helper: use kable for DOCX/PDF, kbl for HTML
# This avoids HTML-specific function detection issues
make_table <- function(data, ...) {
  pandoc_to <- knitr::opts_knit$get("rmarkdown.pandoc.to")
  if (!is.null(pandoc_to) && pandoc_to == "html") {
    return(kableExtra::kbl(data, ...))
  } else {
    return(knitr::kable(data, ...))
  }
}

op <- options(width = 120)
on.exit(options(op), add = TRUE)

`%||%` <- function(x, y) if (is.null(x) || length(x) == 0) y else x

# Note: kable_styling and row_spec are HTML-specific and will cause errors in DOCX/PDF
# We'll use inline conditionals in each table chunk to check format before applying styling

# Find project root - use here() if available, otherwise try multiple strategies
if (requireNamespace("here", quietly = TRUE)) {
  proj_root <- here::here()
} else {
  # Strategy 1: Look for .git directory or README.md starting from current directory
  current_dir <- getwd()
  check_dir <- current_dir
  proj_root <- NULL
  
  for (i in 1:10) {  # Go up at most 10 levels
    if (file.exists(file.path(check_dir, ".git")) || 
        file.exists(file.path(check_dir, "README.md"))) {
      proj_root <- check_dir
      break
    }
    parent <- dirname(check_dir)
    if (parent == check_dir) break  # Reached filesystem root
    check_dir <- parent
  }
  
  # Strategy 2: If we're in reports/, go up 3 levels
  if (is.null(proj_root) && basename(current_dir) == "reports") {
    proj_root <- normalizePath(file.path(current_dir, "../../.."))
  }
  
  # Strategy 3: Default to current directory
  if (is.null(proj_root)) {
    proj_root <- current_dir
  }
}

# Set paths for Chapter 2 data and outputs (updated for new structure)
chapter2_dir <- file.path(proj_root, "07_manuscript", "chapter2")
# Data is now at root level
processed_dir <- file.path(proj_root, "data", "processed")
qc_dir <- file.path(proj_root, "data", "qc")
# Outputs are in numbered folders
figures_dir <- file.path(proj_root, "06_visualization", "output", "figures")
tables_dir <- file.path(proj_root, "06_visualization", "output", "tables")
models_dir <- file.path(proj_root, "06_visualization", "output", "models")

# Helper: figure path resolution
# Returns PNG for HTML output, PDF for DOCX output
# Returns absolute path for file.exists() checks, relative path for include_graphics()
fig_path <- function(fig_name, return_absolute = FALSE) {
  # Get base name without extension
  base_name <- tools::file_path_sans_ext(fig_name)
  
  # Detect output format
  output_format <- NULL
  
  # Method 1: Check knitr's pandoc output format
  pandoc_to <- knitr::opts_knit$get("rmarkdown.pandoc.to")
  if (!is.null(pandoc_to)) {
    output_format <- pandoc_to
  }
  
  # Method 2: Check for DOCX rendering context
  if (is.null(output_format)) {
    docx_indicators <- c(
      knitr::opts_knit$get("quarto.document.format") == "docx",
      grepl("docx", knitr::opts_knit$get("out.format") %||% "", ignore.case = TRUE)
    )
    if (any(docx_indicators, na.rm = TRUE)) {
      output_format <- "docx"
    }
  }
  
  png_name <- paste0(base_name, ".png")
  pdf_name <- paste0(base_name, ".pdf")
  
  # Find the actual file location (use absolute paths for checking)
  png_abs <- NULL
  pdf_abs <- NULL
  
  # Try multiple candidate paths
  candidates_png <- c(
    file.path(figures_dir, png_name),
    file.path(proj_root, "06_visualization", "output", "figures", png_name),
    file.path(proj_root, "07_manuscript", "chapter2", "output", "figures", png_name),
    # Also try relative paths from current working directory
    file.path("../../../06_visualization/output/figures", png_name),
    file.path("../../06_visualization/output/figures", png_name),
    file.path("../06_visualization/output/figures", png_name)
  )
  
  candidates_pdf <- c(
    file.path(figures_dir, pdf_name),
    file.path(proj_root, "06_visualization", "output", "figures", pdf_name),
    file.path(proj_root, "07_manuscript", "chapter2", "output", "figures", pdf_name),
    # Also try relative paths from current working directory
    file.path("../../../06_visualization/output/figures", pdf_name),
    file.path("../../06_visualization/output/figures", pdf_name),
    file.path("../06_visualization/output/figures", pdf_name)
  )
  
  for (path in candidates_png) {
    if (file.exists(path)) {
      png_abs <- normalizePath(path)
      break
    }
  }
  
  for (path in candidates_pdf) {
    if (file.exists(path)) {
      pdf_abs <- normalizePath(path)
      break
    }
  }
  
  # If return_absolute is TRUE, return absolute path (for file.exists checks)
  if (return_absolute) {
    if (!is.null(output_format) && grepl("docx|word", output_format, ignore.case = TRUE)) {
      result <- pdf_abs %||% png_abs
    } else {
      result <- png_abs %||% pdf_abs
    }
    # Return NULL if no file found (file.exists(NULL) will return FALSE)
    return(result)
  }
  
  # Determine relative path based on current working directory
  # From reports/ to project root: reports -> chapter2 -> 07_manuscript -> root (3 levels up)
  # Then down to 06_visualization/output/figures
  if (basename(getwd()) == "reports" || grepl("/reports$", getwd())) {
    rel_path <- "../../../06_visualization/output/figures"
  } else {
    rel_path <- "06_visualization/output/figures"
  }
  
  # Return relative path for rendering
  if (!is.null(output_format) && grepl("docx|word", output_format, ignore.case = TRUE)) {
    if (!is.null(pdf_abs)) {
      return(file.path(rel_path, pdf_name))
    } else if (!is.null(png_abs)) {
      return(file.path(rel_path, png_name))
    }
  } else {
    # HTML: use relative path
    if (!is.null(png_abs)) {
      return(file.path(rel_path, png_name))
    } else if (!is.null(pdf_abs)) {
      return(file.path(rel_path, pdf_name))
    }
  }
  
  # Fallback
  warning("Figure not found: ", fig_name)
  return(file.path(rel_path, if (!is.null(png_abs)) png_name else pdf_name))
}

# Helper: safe read
sread <- function(path) {
  if (length(path) > 1) {
    path <- path[1]
  }
  if (length(path) == 1 && is.character(path) && file.exists(path)) {
    tryCatch(read_csv(path, show_col_types = FALSE), error = function(e) NULL)
  } else {
    NULL
  }
}

# Load data files (if available)
# Trial-level merged data
merged_data <- sread(file.path(processed_dir, "ch2_triallevel_merged.csv"))

# PF parameters
pf_params <- sread(file.path(processed_dir, "ch2_pf_parameters.csv"))

# Quality summaries
quality_summary <- sread(file.path(qc_dir, "pupil_quality_summary.csv"))

# Missingness diagnostic
missingness_results <- sread(file.path(qc_dir, "missingness_diagnostic.csv"))

# Model results
effort_pupil_effects <- sread(file.path(tables_dir, "effort_cog_auc_effects.csv"))
effort_total_auc_effects <- sread(file.path(tables_dir, "effort_total_auc_effects.csv"))
pupil_psychometric_effects <- sread(file.path(tables_dir, "pupil_psychometric_primary_effects.csv"))
pupil_psychometric_lenient <- sread(file.path(tables_dir, "pupil_psychometric_lenient_effects.csv"))
pupil_psychometric_strict <- sread(file.path(tables_dir, "pupil_psychometric_strict_effects.csv"))
pf_pupil_correlations <- sread(file.path(tables_dir, "pf_pupil_coupling_correlations.csv"))
missingness_effects <- sread(file.path(tables_dir, "missingness_diagnostic_effects.csv"))

# LC integrity data (exploratory)
# Try loading from processed directory first, then from master spreadsheet
lc_integrity_file <- file.path(processed_dir, "ch2_lc_integrity.csv")
lc_integrity <- sread(lc_integrity_file)

# If not found, try loading from master spreadsheet
if (is.null(lc_integrity)) {
  master_lc_file <- file.path(proj_root, "data", "raw", "behavioral", "LC Aging Subject Data master spreadsheet - LC integrity.csv")
  if (file.exists(master_lc_file)) {
    lc_integrity <- sread(master_lc_file)
    if (!is.null(lc_integrity)) {
      # Standardize subject ID column name (might be "sub", "subject_id", "BAP", etc.)
      if (!"sub" %in% names(lc_integrity)) {
        if ("subject_id" %in% names(lc_integrity)) {
          lc_integrity$sub <- lc_integrity$subject_id
        } else if ("BAP" %in% names(lc_integrity)) {
          lc_integrity$sub <- lc_integrity$BAP
        }
      }
    }
  }
}

# Demographics
demographics_file <- file.path(processed_dir, "ch2_demographics.csv")
demographics <- sread(demographics_file)

# If not found, try loading from master spreadsheet
if (is.null(demographics)) {
  master_demo_file <- file.path(proj_root, "data", "raw", "behavioral", "LC Aging Subject Data master spreadsheet - demographics.csv")
  if (file.exists(master_demo_file)) {
    demographics <- sread(master_demo_file)
    if (!is.null(demographics)) {
      # Standardize subject ID column name
      if (!"sub" %in% names(demographics)) {
        if ("subject_id" %in% names(demographics)) {
          demographics$sub <- demographics$subject_id
        } else if ("BAP" %in% names(demographics)) {
          demographics$sub <- demographics$BAP
        }
      }
    }
  }
}

neuropsych_file <- file.path(processed_dir, "ch2_neuropsych.csv")
neuropsych <- sread(neuropsych_file)

# LC integrity results (if analyses run)
lc_psychometric_effects <- sread(file.path(tables_dir, "lc_psychometric_extension_effects.csv"))
lc_subset_comparison <- sread(file.path(tables_dir, "lc_subset_bias_check.csv"))
```

\newpage 

# Introduction

## Physical–Cognitive Dual-Task Interactions in Everyday Life and Aging

Everyday life frequently requires people to perform cognitively demanding tasks while simultaneously exerting physical effort. Surgeons must maintain continuous muscle engagement while making fine perceptual discriminations, athletes coordinate complex motor sequences while monitoring environmental cues, and older adults navigate dual-task situations—such as walking while monitoring traffic or carrying groceries while having a conversation—in which physical and cognitive demands interact dynamically. These real-world scenarios highlight a fundamental challenge: when multiple task domains compete for limited cognitive resources, performance in one or both domains may suffer [@wickens2008; @pashler1994dual]. This challenge takes on particular significance in aging, as older adults face both declining cognitive capacity and increased physiological costs of effortful engagement [@salthouse1996; @verhaeghen2003].

A growing literature suggests that physical–cognitive interactions are mediated by shared arousal systems, particularly the locus coeruleus–noradrenergic (LC–NE) system, which modulates sensory gain, evidence accumulation, and response caution as a function of task demands and internal state [@astonjones2005; @mather2016; @jepma2012neural]. Understanding how physical effort modulates cognitive performance—and how this relationship changes with age—requires moving beyond simple outcome measures (overall accuracy or mean reaction time) to characterize how effort-induced arousal alters the fundamental processes underlying perceptual decision-making. The present study addresses this question by combining a physical–cognitive dual-task paradigm with pupillometry and psychometric function analysis to examine how physical effort–induced arousal relates to perceptual sensitivity in older adults.

## Psychometric Functions: Quantifying Perceptual Sensitivity

### Psychometric Functions as Measurement Models

Psychometric functions (PFs) provide a principled framework for characterizing how continuous stimulus intensity relates to perceptual judgments. Rather than collapsing performance across stimulus levels, PFs model the full intensity–response relationship, revealing how the probability of a given response changes as stimulus differences become more or less discriminable. In the present same–different discrimination paradigm, the PF maps a continuous intensity dimension (e.g., frequency offset or contrast difference) onto the probability of responding "different" [@wichmann2001psychometric; @green1966signal; @prins2016psychophysics]. This perspective aligns with a measurement-model view of perception: PFs can be derived from latent sensory evidence that is corrupted by internal noise and then transformed into an overt response via a decision rule [@prins2016psychophysics]. Within this framework, changes in PF steepness are typically interpreted as changes in discriminability (signal-to-noise separation), whereas horizontal shifts can reflect changes in response tendency or criterion, and thus require more cautious interpretation when the task permits bias [@macmillan2005detection].

### Model Specification and Parameter Interpretation

Psychometric functions take sigmoidal (S-shaped) forms and can be expressed using several closely related link families, including the cumulative normal (probit), logistic (logit), and Weibull functions. For a binary response model, one common formulation is the probit PF:

$$P(\text{"different"} | X) = \Phi\left(\frac{X - \alpha}{\beta}\right)$$ {#eq-psychometric}

where $X$ denotes stimulus intensity, $\Phi(\cdot)$ is the cumulative standard normal distribution, $\alpha$ is a location parameter corresponding to the stimulus intensity at which responding reaches a criterion level (often defined at a midpoint between asymptotes), and $\beta$ is a scale/spread parameter. Under this parameterization, PF steepness is inversely related to $\beta$: smaller $\beta$ values yield steeper functions (higher discriminability), whereas larger $\beta$ values yield shallower functions (lower discriminability). The steepness directly reflects discriminability—how rapidly the probability of choosing "different" changes as stimulus intensity increases. Under the probit parameterization, the standard deviation of the underlying sensory noise distribution is $\sigma = \beta$ (the scale parameter directly corresponds to the noise SD). An analogous logit specification replaces $\Phi(\cdot)$ with the logistic function, and in practice different sigmoid families typically yield very similar fits, with differences primarily reflecting parameterization and threshold conventions [@prins2016psychophysics]. For example, the Weibull's conventional threshold parameter corresponds to approximately 0.632 on the cumulative response scale, whereas Quick/log-Quick formulations correspond to 0.5; therefore, threshold values should always be interpreted relative to the criterion at which they are defined [@prins2016psychophysics].

In many psychophysical applications, PFs are described using a four-parameter form that includes asymptotes: a lower asymptote (guess rate, $\gamma$) and an upper asymptote defined by the lapse rate ($\lambda$), in addition to location and scale parameters [@prins2016psychophysics]. In forced-choice accuracy tasks, $\gamma$ is constrained by task structure (e.g., $\gamma=0.5$ in 2AFC; $\gamma=1/M$ in M-AFC). In judgment-based tasks such as same–different responding, the lower asymptote reflects baseline "different" responding (false-alarm tendency) rather than a fixed chance level. The lapse rate $\lambda$ captures stimulus-independent errors (e.g., attentional lapses, motor errors, or track loss) that can prevent performance from reaching the upper bound even at high intensities. Importantly, psychophysical guidance emphasizes that assuming $\lambda=0$ when lapses are present can bias threshold and slope estimates, and that lapse is difficult to estimate reliably without adequate constraints or priors [@prins2016psychophysics; @wichmann2001psychometric]. The full four-parameter formulation is:

$$P(\text{"different"} | X) = \gamma + (1 - \gamma - \lambda) \cdot \Phi\left(\frac{X - \alpha}{\beta}\right)$$

These considerations motivate interpreting location parameters cautiously when criterion and lapses may vary across conditions, while treating changes in steepness as a cleaner index of sensitivity. The location parameter $\alpha$ represents the stimulus intensity at a criterion level—often defined at the midpoint between the lower and upper asymptotes (e.g., halfway between guess rate $\gamma$ and $1-\lambda$), which typically corresponds to approximately 50% "different" responses on the response probability scale. In appearance/judgment tasks where 50% indicates subjective equality (e.g., "brighter vs. darker"), this location is often called a point of subjective equality (PSE). However, in same–different discrimination tasks, the location parameter can reflect a mix of sensitivity and decision criterion/bias [@prins2016psychophysics], so "threshold" or "midpoint" is the more standard terminology. Changes in $\alpha$ may reflect shifts in decision criterion or response bias rather than true sensitivity changes, particularly when criterion can drift with arousal or effort conditions. In forced-choice accuracy PFs, the lower asymptote is constrained by the number of alternatives (e.g., $\gamma = 0.5$ in 2AFC), making "threshold" conventionally defined at a criterion such as 75% correct. In judgment-based PFs (like "different" responses), threshold is often defined at the midpoint between asymptotes (approximately 50% "different" responses), but this location can reflect both sensitivity and criterion/bias. Sensitivity is better reflected in the steepness of the intensity–response relationship (how rapidly probability changes with intensity), which is why the present analyses emphasize slope and its modulation by arousal rather than threshold alone.

The psychometric function is closely related to signal detection theory (SDT), where the location parameter ($\alpha$) corresponds to the decision criterion and the scale parameter ($\beta$) relates to $d'$ (sensitivity). Changes in location reflect criterion shifts (response bias), while changes in steepness (inversely related to $\beta$) reflect true sensitivity changes [@macmillan2005detection]. Some psychophysical procedures (e.g., yes/no detection tasks) are particularly susceptible to criterion shifts, making proportion correct a poor sensitivity measure when response bias varies across conditions or individuals [@prins2016psychophysics]. SDT measures like $d'$ separate sensitivity from bias, providing a more robust index of discriminability. In the present "same–different" judgment task, criterion issues are acknowledged: the location parameter ($\alpha$) is interpreted cautiously as potentially reflecting criterion/bias shifts, whereas sensitivity is emphasized via the steepness parameter ($\beta$ or the intensity coefficient in the GLMM). The hierarchical GLMM framework includes random intercepts to account for individual differences in baseline response tendency (criterion), while the key interaction term tests arousal effects on sensitivity (steepness) rather than merely on response bias.

### Implementation in the Present Study

This chapter leverages two complementary PF approaches that serve distinct purposes. First, descriptive PF parameters (thresholds and slopes) that provide the behavioral backbone for Chapter 2 were estimated previously using Psignifit 4 in MATLAB [@schutt2016painfree], which supports robust estimation and can account for overdispersion. A Weibull PF was fit to each participant's proportion of "different" responses across stimulus levels within each task and effort condition. Because the Weibull function is undefined at zero, the 0-offset intensity level was replaced with half of the smallest non-zero intensity level. Guess and lapse parameters were allowed to vary freely during fitting, and threshold and slope were derived at the effective midpoint—halfway between the estimated guess rate $\gamma$ and $1-\lambda$—yielding a criterion comparable to a 50% point on the effective response scale.

Second, the primary inferential analyses in the present chapter use a hierarchical generalized linear mixed model (GLMM) with a probit link to model trialwise $P(\text{"different"} \mid X)$. In a probit-link GLMM, the linear predictor operates on a latent standard-normal ($z$) evidence scale, and the intensity coefficient governs the steepness of the intensity–response relationship in that latent space. The critical interaction between stimulus intensity and within-person pupil state ($X_{ij} \times P^{(\text{state})}_{ij}$) therefore tests whether moment-to-moment arousal modulates sensitivity (steepness) rather than merely shifting response tendency (criterion). Although the trial-level GLMM does not explicitly estimate lapse parameters, lapse-like contamination is minimized through stringent pupil quality tiers and robustness checks, preserving statistical efficiency while addressing psychophysical concerns about stimulus-independent error. The probit link function is used in the GLMM for consistency with the latent evidence interpretation in signal detection theory, where the cumulative normal distribution naturally maps onto $z$-scaled evidence. In the present study, stimulus intensity is modeled on its original scale (frequency offset in Hz for auditory, contrast difference for visual), and the continuous-intensity GLMM framework avoids binning regardless of the underlying scale.

### Why Continuous-Intensity Modeling

Modeling the continuous intensity–response relationship offers clear advantages over collapsing trials into discrete "easy/hard" bins: it preserves information, yields parameters with interpretable psychological meaning, and improves statistical efficiency by using the full range of stimulus values. Most importantly for the present dissertation aims, steepness provides a direct test of how arousal alters psychometric sensitivity—whether arousal changes the rate at which evidence accumulates across intensity—rather than only changing average responding.

## Arousal, Effort, and Perceptual Sensitivity

The relationship between arousal and cognitive performance has been formalized in several influential frameworks. The Yerkes–Dodson law proposes an inverted-U function in which performance improves with increasing arousal up to an optimal point, beyond which additional arousal—particularly when experienced as stress or anxiety—impairs performance [@yerkes1908]. Adaptive Gain Theory (AGT) provides a mechanistic account centered on the locus coeruleus–norepinephrine (LC–NE) system, linking tonic (baseline) and phasic (event-evoked) LC activity to shifts in neural gain and, ultimately, task performance [@astonjones2005]. Under AGT, optimal performance is expected when tonic LC activity is moderate and phasic responses to task-relevant events are robust, supporting focused attention and efficient responding.

In aging, arousal–performance relationships may be altered in ways that complicate these canonical predictions. Evidence suggests that older adults may exhibit a leftward shift or compression of the inverted-U curve, such that peak performance occurs at lower levels of objective demand relative to younger adults [@mather2016; @mikneviciute2022]. As a result, conditions that are neutral or even beneficial for younger adults may push older adults into supra-optimal arousal states, placing them on the descending limb of the curve and producing performance decrements [@huang2024; @mather2016]. This aging-related vulnerability motivates testing whether experimentally induced arousal—here, physical effort—selectively disrupts the quality of perceptual evidence and the sensitivity of discrimination.

Physical effort provides a controlled method for manipulating arousal state in a way that is experimentally separable from stimulus difficulty. Sustained isometric handgrip at moderate-to-high intensities (e.g., ~30–40% MVC) elicits a robust pressor and sympathoexcitatory response—raising arterial pressure and heart rate and increasing sympathetic outflow—whose magnitude scales with contraction intensity and remains present in older adults. At the neural level, static handgrip and post-exercise ischemia recruit brainstem and cortical regions involved in autonomic control and effort, offering a plausible central substrate for effort-induced arousal shifts that may interact with perceptual decision processes [@lalande2014; @mark1985; @sander2010; @toska2010].

At the same time, physical effort may influence performance through mechanisms that are not purely "arousal," including resource-based interference. Limited-capacity and multiple-resource accounts predict that concurrent physical effort can compete with cognitive task performance when total demands exceed available capacity or when tasks draw on overlapping resource pools [@wickens2008]. Supporting this possibility, Azer et al. [-@azer2023] reported that older adults showed reduced accuracy in a visual working memory task while maintaining moderate handgrip (30% MVC), whereas younger adults were relatively unaffected. This pattern is consistent with the idea that older adults may be more susceptible to combined physical-cognitive demands, either because resources are depleted more readily or because arousal becomes dysregulated under challenge [@verhaeghen2003]. Importantly, these "resource competition" and "arousal regulation" perspectives are not mutually exclusive, and the present study is designed to adjudicate between them by modeling trialwise arousal (pupil state) alongside effort condition.

These frameworks motivate specific predictions for psychometric sensitivity. In a same–different task, the location (midpoint) parameter of the psychometric function can shift if arousal alters decision criterion or response bias—for example, by making participants more conservative or liberal in endorsing "different." Such location shifts do not necessarily indicate true changes in discriminability, and in same–different paradigms location can reflect a mixture of sensitivity and criterion effects; therefore, threshold/location effects are interpreted cautiously. By contrast, the steepness of the psychometric function (inversely related to the scale parameter) provides a cleaner index of sensitivity because it reflects how rapidly response probability changes with stimulus intensity. If effort-induced arousal degrades sensory signal quality or increases internal noise, psychometric functions should become shallower (reduced sensitivity), requiring larger stimulus differences for reliable discrimination. Conversely, if moderate arousal optimizes neural gain and improves signal-to-noise ratio, functions may become steeper (enhanced sensitivity). Critically, these effects may be nonlinear: moderate arousal could improve sensitivity, while supra-optimal arousal—anticipated to occur more readily in older adults—could reduce sensitivity. For this reason, the present analyses emphasize steepness-related effects (and their modulation by pupil-indexed arousal) over threshold shifts alone.

## Pupillometry as a Window into Arousal Dynamics

The LC–NE system is a central regulator of arousal and cognitive state. As the primary source of norepinephrine to the forebrain, LC–NE projections modulate neural gain and the signal-to-noise ratio of cortical processing [@astonjones2005]. AGT posits that task performance depends on a balance between tonic LC activity and phasic LC bursts, such that moderate tonic baseline paired with strong phasic responses supports focused attention and effective behavioral control [@gilzenrat2010].

Pupillometry provides a practical, noninvasive index of arousal dynamics that is often linked to LC–NE activity. Pupil diameter covaries with arousal-related neuromodulatory activity and can be characterized at two levels. First, baseline (tonic) pupil diameter reflects relatively sustained arousal state and has been associated with tonic LC activity and general alertness [@alnaes2014pupil; @gilzenrat2010]. Second, task-evoked pupil responses (TEPRs) reflect event-linked changes often interpreted as phasic arousal and mobilization of mental effort during task execution [@beatty1982; @kahneman1966]. TEPRs typically peak on the order of 1–2 seconds after stimulus onset and can be quantified using peak amplitude, mean dilation over a defined epoch, or the area under the curve (AUC) of the baseline-corrected signal, which jointly captures amplitude and duration. TEPR magnitude has been linked to task difficulty, cognitive load, surprise, and decision confidence, and in discrimination contexts larger TEPRs often accompany more difficult decisions, consistent with increased recruitment of control resources [@kiefer2018; @preuschoff2011pupil; @vanbergen2021]. The neural pathway linking LC to pupil diameter involves direct projections from LC to the Edinger–Westphal nucleus, which controls pupil constriction/dilation via parasympathetic and sympathetic pathways [@joshi2016; @mcDougal2010; @murphy2014].

Interpretation of pupil diameter nevertheless requires care because pupillometry is a multi-determined signal shaped by interacting neural and autonomic pathways. While LC–NE contributions to pupil fluctuations are central to the present theoretical framing, other structures and pathways can also influence pupil dynamics, and measurement artifacts can distort pupil estimates [@papesh2024modern]. In particular, eye position and saccade-related effects can alter apparent pupil size (e.g., pupil foreshortening error and post-saccadic pupil constrictions), and blink-related missingness can bias mean or baseline estimates if not handled carefully [@laeng2024; @hershman2024]. In cognitive tasks, TEPRs reflect event-linked changes that unfold with a physiological delay rather than instantaneously; pupil changes are typically detectable approximately 200–250 ms after task events, with responses tied to specific events such as stimulus presentation, response execution, or feedback [@hershman2024]. This temporal delay justifies the use of epoch-based analysis windows and AUC metrics that capture the full time course of the response. These considerations motivate pairing theory-driven pupil metrics with explicit preprocessing and data-quality procedures designed to minimize artifactual variance and ensure that observed effects reflect task-evoked physiology rather than measurement confounds.

In aging, LC–NE regulation may change in ways that are directly relevant to arousal–performance coupling. Structural degradation of the LC has been observed in older adults [@mather2016], and functional compensatory patterns may emerge, including chronically elevated tonic arousal or altered phasic responsiveness to challenge [@lee2018; @mather2016neural]. Such compensatory dynamics may support performance up to a point, but could also increase vulnerability to supra-optimal arousal, leading to distractibility and degraded information processing under high demand [@astonjones2005; @eldar2013]. Pupillometry studies in aging report heterogeneous patterns—often larger baseline pupils coupled with reduced task-evoked responses—suggesting altered tonic-phasic balance [@granholm2007; @vanbergen2021]. Physical effort manipulations therefore provide an opportunity to test whether externally induced arousal shifts pupil dynamics and whether trialwise pupil state predicts changes in psychometric sensitivity.

## Dual-Task Context and Competing Mechanisms

Dual-task paradigms have long been used to understand limits of attention and performance under concurrent demands. Limited-capacity and resource-competition accounts propose that performance decrements arise when combined task demands exceed available resources, particularly when tasks draw on overlapping pools of attention or executive control [@kahneman1973; @navon1984; @navon1985; @wickens2008]. Multiple Resource Theory further predicts that interference depends on similarity across resource dimensions (e.g., spatial vs. verbal demands), such that tasks that share processing channels are more likely to interfere [@wickens2008]. Applied to physical–cognitive dual tasks, interference may arise through sustained attentional requirements for maintaining force, physiological arousal effects that can help or harm performance depending on state, and motor–cognitive competition that affects response selection and execution [@proctor2012; @woollacott2002]. Age-related increases in dual-task costs are well documented and may reflect reduced reserve, altered executive control, or changes in arousal regulation [@beurskens2014; @verhaeghen2003].

The present study explicitly recognizes that effort effects may reflect both generic resource competition and arousal-mediated mechanisms. Resource-competition models predict effort-related performance decrements as demands rise, whereas arousal-based accounts (including LC–NE mechanisms) predict that the quality of information processing may change as a function of arousal state, potentially independent of capacity limits. The key advantage of pairing pupillometry with psychometric modeling is that it allows these mechanisms to be separated empirically: effort condition provides an experimental manipulation, while trialwise pupil state indexes moment-to-moment arousal, and the psychometric framework distinguishes sensitivity changes (steepness) from criterion shifts (intercept/location). Accordingly, effort main effects in the GLMM may reflect a mixture of resource and arousal influences, whereas a significant stimulus intensity × pupil-state interaction would more specifically support arousal-linked modulation of sensitivity.

## Linking Arousal to Psychometric Sensitivity: Analytic Strategy

Traditional analyses of arousal–performance often collapse continuous stimulus intensity into coarse difficulty bins (e.g., "easy" vs. "hard"), which discards information and obscures how arousal modulates the intensity–response relationship itself. The present chapter instead models trialwise responses across the continuous intensity dimension, enabling direct estimation of psychometric sensitivity and its modulation by arousal.

A central methodological challenge in pupil–behavior analyses is separating within-person "state" fluctuations from between-person "trait" differences. To do so, each pupil metric ($P_{ij}$) is decomposed into a subject-mean component and a trial-wise deviation using within-subject centering:

$$P^{(\text{trait})}_{j} = \overline{P}_{j}, \qquad P^{(\text{state})}_{ij} = P_{ij} - \overline{P}_{j}$$ {#eq-state-trait}

This decomposition enables two distinct questions to be tested in the same model: whether individuals with higher average arousal differ in sensitivity (trait effects), and whether trials on which an individual is more aroused than usual show altered sensitivity (state effects). Importantly, this approach prevents conflating between- and within-person patterns—an especially relevant concern in aging where trait differences may be influenced by health, LC integrity, or cognitive reserve [@enders2013; @hoffman2015]. For example, if high-arousal individuals tend to have poorer performance for reasons unrelated to trial-wise fluctuations (e.g., underlying LC degeneration or comorbidities), that pattern will be captured at the trait level rather than falsely attributed to trial-wise changes in arousal.

Primary inference is implemented using hierarchical generalized linear mixed models (GLMMs) with a probit link, modeling trialwise $P(Y_{ij}=1)$ as a function of continuous stimulus intensity, effort condition, modality, and pupil-indexed arousal while accounting for individual differences via random effects:

$$
\begin{aligned}
\text{probit}(P(Y_{ij}=1)) &= \beta_0 + \beta_1 X_{ij} + \beta_2 \text{Effort}_{ij} + \beta_3 \text{Modality}_{ij} + \beta_4 P^{(\text{state})}_{ij} \\
&\quad + \beta_5 (X_{ij} \times P^{(\text{state})}_{ij}) + \beta_6 P^{(\text{trait})}_{j} + u_{0j} + u_{1j}X_{ij}
\end{aligned}
$$ {#eq-primary-glmm}

where $Y_{ij}$ is the binary outcome on trial $i$ for subject $j$, $X_{ij}$ is the continuous stimulus intensity, $\text{Effort}_{ij}$ codes the handgrip effort condition (High vs. Low), and $\text{Modality}_{ij}$ codes the sensory modality (auditory vs. visual). $P^{(\text{state})}_{ij}$ and $P^{(\text{trait})}_{j}$ are the state and trait components of the pupil metric, respectively, and $u_{0j}$ and $u_{1j}$ are subject-specific random intercepts and random slopes on $X_{ij}$, allowing each participant to have their own baseline performance level and intensity sensitivity.

In this framework, the key parameter is the stimulus intensity × pupil-state interaction ($\beta_5$), which tests whether moment-to-moment arousal modulates psychometric sensitivity. A significant interaction indicates that the intensity–response slope differs as a function of trialwise arousal—consistent with arousal-linked changes in sensitivity—whereas changes limited to intercept/location terms would be more consistent with shifts in response tendency or criterion.

## Research Questions and Hypotheses

Based on the theoretical rationale above, the present study addresses four research questions. First, we test how high (40% MVC) versus low (5% MVC) effort affects behavioral psychometric function parameters (thresholds and slopes) in older adults performing auditory and visual same–different discrimination. We expect midpoint thresholds to be higher under high effort, acknowledging that threshold shifts may reflect sensitivity and/or criterion changes, and we predict shallower slopes under high effort, consistent with reduced discriminability under elevated arousal.

Second, we test whether high effort increases tonic and task-evoked pupil dynamics relative to low effort. We predict larger baseline pupil diameter and larger TEPR (AUC) under high effort, indicating elevated tonic and phasic arousal, respectively.

Third, we test whether trialwise phasic arousal predicts psychometric sensitivity when intensity is modeled continuously. The primary hypothesis is that the stimulus intensity × pupil-state interaction will be negative (shallower slopes on higher-arousal trials), consistent with supra-optimal arousal increasing noise or degrading signal quality; an alternative hypothesis is that moderate arousal could enhance sensitivity, yielding a positive interaction. We also expect weaker or null associations for pupil-trait predictors, given that trait effects may be confounded with other individual differences such as LC integrity or cognitive reserve.

Finally, we test whether individuals with larger effort-evoked arousal changes (Δpupil) exhibit larger effort-related changes in psychometric parameters (Δthreshold, Δslope), predicting that stronger physiological reactivity is associated with larger behavioral decrements.

# Methods

<!-- Add your methods section here -->

## Participants

Approximately 50 healthy older adults (target N ≈ 50 after QC; final N may vary modestly), aged 65+ years, completed the dual-task paradigm.

## Task Paradigm

Participants performed **same–different discrimination** tasks in two modalities while simultaneously squeezing a dynamometer:

**Effort Conditions:**

- **Low effort:** 5% of maximum voluntary contraction (MVC)

- **High effort:** 40% MVC

**Stimuli:**

- **Auditory Discrimination Task (ADT):** 1000 Hz base tones with frequency offsets of +8, +16, +32, or +64 Hz

- **Visual Discrimination Task (VDT):** Oriented Gabor patches with contrast differences of +0.06, +0.12, +0.24, or +0.48

**Trial Structure:**
Each trial followed this sequence:
1. Pre-squeeze baseline: 3 seconds
2. Sustained squeeze period: 3 seconds (Low or High effort)
3. Standard stimulus: 0.1 seconds
4. Inter-stimulus interval (ISI): 0.5 seconds
5. Target stimulus: 0.1 seconds
6. Response window: Participants indicated whether the target was "same" or "different" from the standard

## Pupillometry

Pupil diameter was recorded continuously throughout each trial using an eye-tracking system. The data were processed using a MATLAB preprocessing pipeline that segments trials relative to squeeze onset, flags blinks and track loss events, computes window-specific validity metrics, and implements baseline correction using pre-event windows.

### Pupil Features

Two primary features were computed on each trial:

1. **Total AUC:** Baseline-corrected area under the pupil curve over a global trial window, indexing overall arousal during concurrent physical effort.

2. **Cognitive pupil metric (primary):** Baseline-corrected task-evoked measure computed in a fixed-duration post-target window (e.g., from 300 ms after target onset through a fixed 1 s window), designed to reduce confounding by response time and late-trial dropout.

### Quality Tiers

Pupil-based analyses used pre-specified quality tiers:

- **Primary tier:** Window validity ≥ 0.60 for baseline and cognitive windows
- **Lenient tier:** Window validity ≥ 0.50 (robustness check)
- **Strict tier:** Window validity ≥ 0.70 (robustness check)

**Rationale for Quality Tiers: Lapse-Rate Considerations in Aging**

Psychophysical modeling guidance emphasizes that **assuming lapse rate ($\lambda$) = 0 can distort threshold and slope estimates** if lapses are present but unaccounted for [@prins2016psychophysics]. This concern is particularly relevant in older adult populations, where attentional lapses, track loss events, and data quality issues may be more frequent. The quality tier strategy addresses this by excluding trials with poor pupil data quality (low validity), thereby reducing lapse-like contamination in the psychometric function estimates. The tiering approach tests robustness of conclusions across stricter inclusion criteria: if key effects (e.g., the stimulus intensity × pupil state interaction) are consistent across lenient (≥0.50), primary (≥0.60), and strict (≥0.70) validity thresholds, this provides evidence that findings are not driven by lapse-like errors or data quality artifacts. This strategy is consistent with psychophysical best practices for handling stimulus-independent errors without explicitly estimating lapse parameters in the primary model [@prins2016psychophysics].

## Locus Coeruleus (LC) Integrity

### LC Integrity Quantification

For a subset of participants, structural magnetic resonance imaging (MRI) data were available to quantify LC integrity. LC integrity was assessed using contrast-based metrics derived from magnetization transfer contrast (MTC) imaging, following the methodology described in Bennett et al. (2024, *Scientific Reports*). The primary LC integrity metric was computed as the mean MTC signal within the LC mask relative to the pons reference region (MTC~LC/pons~). This mean-within-mask approach was chosen over maximum-voxel extraction because it is more robust to uneven LC degeneration patterns that can affect maximum-voxel metrics [@bennett2024locus]. Additionally, diffusion-based metrics (e.g., restricted diffusion fraction) were available as complementary integrity indices, with prior work suggesting that diffusion metrics may relate to cognitive performance independent of age [@bennett2024locus].

### Conceptual Relevance

LC structural integrity provides a trait-level index of neuromodulatory capacity that complements the state-level (trial-wise) and trait-level (between-subject mean) pupil metrics. The LC–NE system serves as the primary source of norepinephrine to the forebrain and modulates cortical gain according to Adaptive Gain Theory [@astonjones2005]. Structural integrity of the LC may constrain both baseline (tonic) and task-evoked (phasic) LC–NE function, potentially explaining individual differences in arousal reactivity and its relationship to cognitive performance. In the context of Chapter 2's focus on pupil-indexed arousal and psychometric sensitivity, LC integrity may help explain why some individuals show stronger or weaker coupling between arousal state and perceptual sensitivity, beyond what is captured by pupil trait (mean arousal level).

### LC Integrity Analyses: Exploratory Extension

LC integrity analyses are positioned as **exploratory and secondary** to the primary pupil–psychometric coupling analyses specified in the prospectus. These analyses were motivated by the theoretical framework's emphasis on LC–NE mechanisms and by the recognition that trait-level pupil metrics (mean arousal) may be confounded with underlying LC structural integrity or other individual-difference factors (e.g., cognitive reserve, general health). However, because LC integrity data were not part of the original prospectus and are available for only a subset of participants, these analyses are treated as exploratory extensions that may inform future research rather than as confirmatory tests of primary hypotheses.

## Statistical Analysis

### Psychometric Function Fitting

Psychometric function parameters (thresholds and slopes) used as the behavioral backbone were estimated using **Psignifit 4** (MATLAB; @schutt2016painfree), which supports robust estimation and can account for overdispersion. A **Weibull psychometric function** was fit to the proportion of "different" responses across continuous stimulus intensity levels, separately for each participant × task/modality × effort condition. Because the Weibull function is undefined at zero stimulus intensity, the 0-offset level was replaced with **half of the smallest non-zero stimulus intensity**. **Guess and lapse parameters were allowed to vary freely** during fitting (i.e., $\gamma$ and $\lambda$ were free parameters), consistent with psychophysical guidance that fixing lapse at zero can bias threshold and slope estimates when lapses are present [@prins2016psychophysics; @wichmann2001psychometric]. Threshold and slope were derived at the **effective midpoint** between the estimated guess rate $\gamma$ and $1-\lambda$ (i.e., at $\gamma + (1-\gamma-\lambda)/2$, which corresponds to approximately 0.5 on the effective response probability scale). This midpoint-based threshold definition ensures that threshold reflects the stimulus level at which "different" responses occur at the midpoint between the lower and upper asymptotes, providing a criterion that is robust to variations in guess and lapse rates and making interpretation comparable across different PF families and parameterizations.

### Model Checking and Goodness-of-Fit

Likelihood-based psychometric function modeling typically evaluates fit using likelihood-ratio/deviance approaches, and PF-based inference relies on assumptions of **stability and independence** across trials [@prins2016psychophysics]. In the present hierarchical GLMM framework, model selection and goodness-of-fit are assessed through several complementary approaches: (a) **AIC comparisons** between models with and without key interaction terms (e.g., stimulus intensity × pupil state), where lower AIC values indicate better fit; (b) **robustness checks** across multiple quality tiers (lenient, primary, strict), testing whether key effects are stable across different data inclusion criteria; and (c) **convergence diagnostics** for mixed-effects models (e.g., gradient checks, optimizer settings). The hierarchical structure accounts for within-subject dependencies through random effects, and the continuous-intensity GLMM avoids the trial-binning assumptions that can affect traditional PF fitting. While parametric or nonparametric bootstrap approaches can provide additional uncertainty quantification for PF parameters [@prins2016psychophysics], the present GLMM framework uses likelihood-based confidence intervals and robustness checks across quality tiers as the primary approach to evaluating parameter stability and inference validity.

### Primary GLMM

The primary model used a probit link function to link phasic arousal to psychometric sensitivity:

$$
\begin{aligned}
\text{probit}(P(Y_{ij}=1)) &= \beta_0 + \beta_1 X_{ij} + \beta_2 \text{Effort}_{ij} + \beta_3 \text{Modality}_{ij} + \beta_4 P^{(\text{state})}_{ij} \\
&\quad + \beta_5 (X_{ij} \times P^{(\text{state})}_{ij}) + \beta_6 P^{(\text{trait})}_{j} + u_{0j} + u_{1j}X_{ij}
\end{aligned}
$$


where $Y_{ij}$ is the binary choice on trial $i$ for subject $j$, $X_{ij}$ is continuous stimulus intensity, $P^{(\text{state})}_{ij}$ is the within-subject centered pupil metric (trial value - subject mean), and $P^{(\text{trait})}_{j}$ is the between-subject pupil metric (subject mean). The key interaction term $X_{ij} \times P^{(\text{state})}_{ij}$ (coefficient $\beta_5$) tests whether within-person fluctuations in arousal are associated with changes in psychometric sensitivity. The term $\beta_6 P^{(\text{trait})}_{j}$ tests whether between-subject differences in average arousal relate to sensitivity, while controlling for state-level effects. The random effects $u_{0j}$ and $u_{1j}$ allow each participant to have their own baseline performance level and intensity sensitivity, respectively.

### Sensitivity Analysis and Robustness Checks

To ensure the robustness of our primary findings, we conducted several sensitivity analyses:

**1. Quality Tier Robustness Checks**

The primary analysis used the primary quality tier (baseline and cognitive window validity ≥ 0.60). To assess whether results were sensitive to data quality thresholds, we re-ran the primary GLMM using two alternative quality tiers:

- **Lenient tier:** Window validity ≥ 0.50 (includes more trials, potentially with lower data quality)
- **Strict tier:** Window validity ≥ 0.70 (includes fewer trials, but with higher data quality)

If the key interaction effect (stimulus intensity × pupil state) is consistent across all three quality tiers, this provides evidence that the finding is robust to different data inclusion criteria.

**2. Model Comparison**

To evaluate whether the interaction term meaningfully improves model fit, we compared the primary model (with the stimulus intensity × pupil state interaction) to an alternative model that excluded the interaction term. Models were compared using Akaike Information Criterion (AIC), where lower AIC values indicate better model fit. A substantial improvement in fit (ΔAIC > 2) for the model with the interaction would support the inclusion of this term and the interpretation that pupil state modulates psychometric sensitivity.

**3. Missingness Diagnostic**

As described in the Missingness Diagnostic section, we tested whether missing pupil data were systematically related to experimental conditions (effort, stimulus intensity, task) or behavioral measures (response time). If missingness is random or only related to non-experimental variables, this supports the validity of the primary analyses.

### Exploratory LC Integrity Extension

For participants with available LC integrity data, we extended the primary GLMM to examine whether LC structural integrity moderates the relationship between pupil-indexed arousal and psychometric sensitivity. The extended model includes:

$$
\begin{aligned}
\text{probit}(P(Y_{ij}=1)) &= \beta_0 + \beta_1 X_{ij} + \beta_2 \text{Effort}_{ij} + \beta_3 \text{Modality}_{ij} + \beta_4 P^{(\text{state})}_{ij} \\
&\quad + \beta_5 (X_{ij} \times P^{(\text{state})}_{ij}) + \beta_6 P^{(\text{trait})}_{j} + \beta_7 \text{LC}_j \\
&\quad + \beta_8 (X_{ij} \times P^{(\text{state})}_{ij} \times \text{LC}_j) + \beta_9 \text{Age}_j + \beta_{10} \text{Sex}_j \\
&\quad + \beta_{11} \text{Education}_j + u_{0j} + u_{1j}X_{ij}
\end{aligned}
$$


where $\text{LC}_j$ is the LC integrity metric (mean MTC~LC/pons~) for subject $j$, and the three-way interaction $X_{ij} \times P^{(\text{state})}_{ij} \times \text{LC}_j$ tests whether LC integrity moderates the coupling between pupil state and psychometric sensitivity. Age, sex, and education are included as covariates to control for potential confounds. The random effects structure remains consistent with the primary model. These analyses are exploratory given that (a) LC integrity data were not part of the original prospectus, (b) LC data are available for only a subset of participants, and (c) the primary focus remains on pupil–psychometric coupling rather than LC integrity per se.

### Analysis Plan: Confirmatory vs. Exploratory

The primary analyses specified in the prospectus are treated as **confirmatory**:
- Effort effects on psychometric function parameters (RQ1)
- Effort–pupil manipulation check (RQ2)
- Trial-level pupil–psychometric coupling (RQ3, primary analysis)
- Subject-level PF–pupil coupling (RQ4)

**Sensitivity analyses** (quality tier robustness checks, model comparison) are pre-specified and serve to evaluate the robustness of primary findings.

**Exploratory analyses** include:
- LC integrity moderation analyses (not in original prospectus)
- Any post-hoc analyses suggested by the data

# Results

The following sections present results from the complete analysis pipeline, including behavioral psychometric function parameters, effort–pupil manipulation checks, missingness diagnostics, primary pupil–psychometric coupling analyses, and subject-level individual differences. All analyses were conducted using the primary quality tier (baseline and cognitive window validity ≥ 0.60) unless otherwise specified.

## Data Quality and Sample Sizes

```{r data-quality}
#| label: tbl-data-quality
#| tbl-cap: "Data Quality Summary: Pupil Data Availability by Task and Effort"

if (!is.null(quality_summary)) {
  quality_summary %>%
    group_by(task) %>%
    summarise(
      n_subjects = n_distinct(sub),
      n_trials_total = sum(n_trials, na.rm = TRUE),
      n_primary = sum(n_primary, na.rm = TRUE),
      prop_primary = mean(prop_primary, na.rm = TRUE),
      mean_baseline_quality = mean(mean_baseline_quality, na.rm = TRUE),
      mean_cog_quality = mean(mean_cog_quality, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    make_table(
      col.names = c("Task", "N Subjects", "Total Trials", "Primary Tier", 
                   "Prop Primary", "Mean Baseline Quality", "Mean Cognitive Quality"),
      digits = 3
    )
} else if (!is.null(merged_data)) {
  # Fallback: compute from merged data
  if ("quality_primary" %in% names(merged_data)) {
    quality_summary_alt <- merged_data %>%
      group_by(task, effort) %>%
      summarise(
        n_trials = n(),
        n_primary = sum(quality_primary == TRUE, na.rm = TRUE),
        prop_primary = mean(quality_primary == TRUE, na.rm = TRUE),
        .groups = "drop"
      )
    
    quality_summary_alt %>%
      make_table(
        col.names = c("Task", "Effort", "N Trials", "Primary Tier", "Proportion"),
        digits = 3
      )
  } else if ("gate_pupil_primary" %in% names(merged_data)) {
    # Use gate_pupil_primary if quality_primary doesn't exist
    quality_summary_alt <- merged_data %>%
      group_by(task, effort) %>%
      summarise(
        n_trials = n(),
        n_primary = sum(gate_pupil_primary == TRUE, na.rm = TRUE),
        prop_primary = mean(gate_pupil_primary == TRUE, na.rm = TRUE),
        .groups = "drop"
      )
    
    quality_summary_alt %>%
      make_table(
        col.names = c("Task", "Effort", "N Trials", "Primary Tier", "Proportion"),
        digits = 3
      )
  } else {
    cat("*Quality columns not found in merged data.*")
  }
} else {
  cat("*Data quality summary not yet available.*")
}
```

## Behavioral Backbone (PF Outcomes)

```{r pf-backbone}
#| label: tbl-pf-params
#| tbl-cap: "Psychometric Function Parameters by Task and Effort"

if (!is.null(pf_params)) {
  pf_summary <- pf_params %>%
    filter(converged) %>%
    group_by(task, effort) %>%
    summarise(
      n = n(),
      threshold_mean = mean(threshold, na.rm = TRUE),
      threshold_sd = sd(threshold, na.rm = TRUE),
      slope_mean = mean(slope, na.rm = TRUE),
      slope_sd = sd(slope, na.rm = TRUE),
      .groups = "drop"
    )
  
  pf_summary %>%
    make_table(
      col.names = c("Task", "Effort", "N", "Threshold (M)", "Threshold (SD)", 
                   "Slope (M)", "Slope (SD)"),
      digits = 3,
      caption = "Psychometric Function Parameters by Task and Effort"
    )
} else {
  cat("*PF parameters not yet computed.*")
}
```

Psychometric function parameters (thresholds and slopes) were estimated separately for each subject × task × effort combination using probit link functions with continuous stimulus intensity.

**Hypothesis Testing:** Hypothesis 1a predicted that midpoint thresholds would be higher under High effort relative to Low effort, which could reflect degraded signal-to-noise ratios (sensitivity changes) or shifts in decision criterion (bias changes), as threshold in same–different paradigms can reflect both. Hypothesis 1b predicted that slopes would be shallower (lower sensitivity, higher $\beta$) under High effort, indicating increased variability in perceptual judgments when arousal is elevated. Steepness (inversely related to $\beta$) is emphasized as the primary sensitivity index, as it is less confounded by criterion shifts than threshold. These hypotheses were tested by comparing PF parameters between High and Low effort conditions within each task modality.

```{r pf-backbone-fig}
#| label: fig-pf-backbone
#| fig-cap: "Psychometric Functions by Effort Condition"
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"

fig_path_abs <- fig_path("fig1_psychometric_by_effort.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("fig1_psychometric_by_effort.png"))
} else {
  cat("*Figure: fig1_psychometric_by_effort.png not yet generated.*")
}
```

## Effort–Pupil Manipulation Check

```{r effort-pupil-check}
#| label: tbl-effort-pupil
#| tbl-cap: "Effort Effect on Pupil Metrics"

if (!is.null(effort_pupil_effects) || !is.null(effort_total_auc_effects)) {
  # Combine both Total AUC and Cognitive AUC results
  effort_results_list <- list()
  
  if (!is.null(effort_total_auc_effects)) {
    effort_results_list$total <- effort_total_auc_effects %>%
      filter(term == "effort_factorHigh") %>%
      mutate(metric = "Total AUC") %>%
      select(metric, estimate, std.error, statistic)
  }

if (!is.null(effort_pupil_effects)) {
    effort_results_list$cog <- effort_pupil_effects %>%
      filter(term == "effort_factorHigh") %>%
      mutate(metric = "Cognitive AUC") %>%
      select(metric, estimate, std.error, statistic)
  }
  
  if (length(effort_results_list) > 0) {
    effort_results <- bind_rows(effort_results_list)
    
    effort_results %>%
      make_table(
        col.names = c("Pupil Metric", "Estimate", "SE", "t"),
        digits = 3,
        caption = "Effort Effect on Pupil Metrics (High vs Low Effort)"
      )
  } else {
    cat("*Effort–pupil manipulation check results not yet available.*")
  }
} else {
  cat("*Effort–pupil manipulation check results not yet available.*")
}
```

High-effort handgrip increased pupil dynamics relative to Low effort, confirming effective engagement of central arousal systems. Mixed-effects models tested whether effort condition predicted pupil metrics (Total AUC and Cognitive AUC) while controlling for task modality.

**Hypothesis Testing:** Hypothesis 2a predicted that baseline (tonic) pupil diameter would be larger under High effort, and Hypothesis 2b predicted that task-evoked pupil responses (AUC) would be larger under High effort. Both hypotheses were supported if High effort significantly increased Total AUC and Cognitive AUC relative to Low effort, providing a physiological manipulation check that physical effort modulates central arousal systems in older adults.

```{r effort-pupil-fig}
#| label: fig-effort-pupil
#| fig-cap: "Effort–Pupil Manipulation Check"
#| fig-width: 10
#| fig-height: 8
#| out-width: "100%"

fig_path_abs <- fig_path("fig2_effort_pupil_manipulation.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("fig2_effort_pupil_manipulation.png"))
} else {
  fig_path_abs2 <- fig_path("effort_manipulation_cog_auc.png", return_absolute = TRUE)
  if (!is.null(fig_path_abs2) && file.exists(fig_path_abs2)) {
  knitr::include_graphics(fig_path("effort_manipulation_cog_auc.png"))
} else {
    cat("*Figure: fig2_effort_pupil_manipulation.png not yet generated.*")
  }
}
```

## Missingness Diagnostic

Missingness analyses tested whether pupil data retention was predicted by effort, stimulus intensity, modality, or response time using logistic mixed-effects models. This diagnostic is critical for assessing potential systematic bias in pupil data availability.

```{r missingness}
#| label: tbl-missingness
#| tbl-cap: "Missingness Diagnostic: Predictors of Pupil Data Usability"

if (!is.null(missingness_effects)) {
  missingness_effects %>%
    filter(term != "(Intercept)") %>%
    select(term, estimate, std.error, statistic, p.value) %>%
    mutate(
      term = str_replace_all(term, c(
        "effort_factorHigh" = "Effort (High vs Low)",
        "stimulus_intensity_scaled" = "Stimulus Intensity",
        "task_factorVDT" = "Task (VDT vs ADT)",
        "rt_scaled" = "Response Time"
      ))
    ) %>%
    make_table(
      col.names = c("Predictor", "Estimate (OR)", "SE", "z", "p"),
      digits = 3
    )
} else {
  cat("*Missingness diagnostic results not yet available.*")
}
```

```{r missingness-fig}
#| label: fig-missingness
#| fig-cap: "Missingness Diagnostic: RT by Pupil Data Availability"
#| fig-width: 8
#| fig-height: 6
#| out-width: "100%"

fig_path_abs <- fig_path("fig4_missingness_diagnostic.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("fig4_missingness_diagnostic.png"))
} else {
  cat("*Figure: fig4_missingness_diagnostic.png not yet generated.*")
}
```

[Results interpretation: If effort significantly predicts missingness, this indicates potential bias that should be acknowledged in interpretation. If missingness is random or predicted only by non-experimental variables, this supports the validity of the primary analyses.]

## Pupil–Psychometric Coupling (Primary Analysis)

```{r primary-coupling}
#| label: tbl-pupil-psychometric
#| tbl-cap: "Primary GLMM: Pupil–Psychometric Coupling"

if (!is.null(pupil_psychometric_effects)) {
  # Build base table
  tbl <- pupil_psychometric_effects %>%
    select(term, estimate, std.error, statistic, p.value) %>%
    make_table(
      col.names = c("Term", "Estimate", "SE", "z", "p"),
      digits = 4
    )
  
  # Return plain table (styling removed for DOCX/PDF compatibility)
  tbl
} else {
  cat("*Primary coupling analysis results not yet available.*")
}
```

The primary analysis tested whether trial-wise phasic arousal (pupil state) predicts psychometric sensitivity when stimulus intensity is modeled continuously. The key test is the interaction between stimulus intensity and pupil cognitive state, which directly assesses whether within-person fluctuations in arousal modulate psychometric sensitivity.

**Hypothesis Testing:** Hypothesis 3a predicted that the interaction between stimulus intensity and pupil state ($X_{ij} \times P^{(\text{state})}_{ij}$) would be negative, indicating that higher trial-level arousal is associated with shallower psychometric slopes (reduced sensitivity), consistent with supra-optimal arousal degrading signal quality. The alternative Hypothesis 3b allowed for a positive interaction if moderate arousal enhances sensitivity. Hypothesis 3c predicted minimal effects of pupil trait (between-subject baseline arousal) on sensitivity, as trait effects may be confounded with other individual differences.

**Interpretation of Results:** If the interaction term is non-significant, this suggests that within-person fluctuations in arousal (pupil state) do not reliably modulate psychometric sensitivity beyond the effects of effort condition. This could indicate that (a) effort main effects (captured by the effort factor in the model) are the primary drivers of sensitivity changes, potentially reflecting resource competition rather than moment-to-moment arousal fluctuations, (b) the relationship between arousal and sensitivity is weaker than expected in older adults, or (c) the fixed-window cognitive pupil metric may not capture the most relevant arousal dynamics for psychometric sensitivity. However, a non-significant interaction does not negate the possibility that effort-induced arousal changes affect performance at the group level (via effort main effects); it suggests that trial-wise arousal fluctuations may not be the primary mechanism. The robustness checks across quality tiers and model comparison help evaluate whether this pattern is consistent and whether the interaction term meaningfully improves model fit.

```{r pupil-psychometric-fig}
#| label: fig-pupil-psychometric
#| fig-cap: "Psychometric Functions by Pupil State (Primary Analysis)"
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"

fig_path_abs <- fig_path("fig3_psychometric_by_pupil_state.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("fig3_psychometric_by_pupil_state.png"))
} else {
  fig_path_abs2 <- fig_path("psychometric_by_pupil_state.png", return_absolute = TRUE)
  if (!is.null(fig_path_abs2) && file.exists(fig_path_abs2)) {
  knitr::include_graphics(fig_path("psychometric_by_pupil_state.png"))
} else {
    cat("*Figure: fig3_psychometric_by_pupil_state.png not yet generated.*")
  }
}
```

```{r pupil-psychometric-interaction-fig}
#| label: fig-pupil-psychometric-interaction
#| fig-cap: "Model Predictions: Stimulus × Pupil State Interaction"
#| fig-width: 10
#| fig-height: 8
#| out-width: "100%"

fig_path_abs <- fig_path("pupil_psychometric_interaction.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("pupil_psychometric_interaction.png"))
} else {
  cat("*Figure: pupil_psychometric_interaction.png not yet generated.*")
}
```

### Robustness Checks and Sensitivity Analyses

To assess the robustness of our primary findings, we conducted several sensitivity analyses:

**1. Quality Tier Robustness Checks**

Results were tested across multiple quality tiers (lenient ≥0.50, primary ≥0.60, strict ≥0.70) to ensure robustness to different data inclusion criteria. If the key interaction effect is consistent across all three quality tiers, this provides evidence that the finding is robust to different data quality thresholds.

```{r robustness-checks}
#| label: tbl-robustness
#| tbl-cap: "Robustness Checks: Interaction Effect Across Quality Tiers"

if (!is.null(pupil_psychometric_effects) && 
    !is.null(pupil_psychometric_lenient) && 
    !is.null(pupil_psychometric_strict)) {
  
  # Extract interaction terms
  interaction_primary <- pupil_psychometric_effects %>%
    filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
  
  interaction_lenient <- pupil_psychometric_lenient %>%
    filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
  
  interaction_strict <- pupil_psychometric_strict %>%
    filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
  
  # Extract interaction terms safely
  get_interaction <- function(df) {
    if (nrow(df) > 0) {
      int_row <- df %>% filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
      if (nrow(int_row) > 0) {
        return(list(
          estimate = int_row$estimate[1],
          se = int_row$std.error[1],
          z = int_row$statistic[1],
          p = if ("p.value" %in% names(int_row)) int_row$p.value[1] else NA
        ))
      }
    }
    return(list(estimate = NA, se = NA, z = NA, p = NA))
  }
  
  lenient_int <- get_interaction(pupil_psychometric_lenient)
  primary_int <- get_interaction(pupil_psychometric_effects)
  strict_int <- get_interaction(pupil_psychometric_strict)
  
  robustness_table <- tibble(
    Quality_Tier = c("Lenient (≥0.50)", "Primary (≥0.60)", "Strict (≥0.70)"),
    Estimate = c(lenient_int$estimate, primary_int$estimate, strict_int$estimate),
    SE = c(lenient_int$se, primary_int$se, strict_int$se),
    z = c(lenient_int$z, primary_int$z, strict_int$z),
    p = c(lenient_int$p, primary_int$p, strict_int$p)
  )
  
  robustness_table %>%
    make_table(
      col.names = c("Quality Tier", "Estimate", "SE", "z", "p"),
      digits = 4
    )
} else {
  cat("*Robustness check results not yet available.*")
}
```

**2. Model Comparison**

To evaluate whether the interaction term meaningfully improves model fit, we compared the primary model (with stimulus intensity × pupil state interaction) to an alternative model without the interaction term. Models were compared using Akaike Information Criterion (AIC), where lower AIC values indicate better fit.

```{r model-comparison}
#| label: tbl-model-comparison
#| tbl-cap: "Model Comparison: With vs. Without Interaction Term"

# Load models if available
mod_primary_path <- file.path(models_dir, "mod_pupil_psychometric_primary.rds")
mod_no_int_path <- file.path(models_dir, "mod_pupil_psychometric_no_interaction.rds")

# Try alternative paths if needed
if (!file.exists(mod_primary_path)) {
  alt_path <- file.path(proj_root, "06_visualization", "output", "models", "mod_pupil_psychometric_primary.rds")
  if (file.exists(alt_path)) mod_primary_path <- alt_path
}
if (!file.exists(mod_no_int_path)) {
  alt_path <- file.path(proj_root, "06_visualization", "output", "models", "mod_pupil_psychometric_no_interaction.rds")
  if (file.exists(alt_path)) mod_no_int_path <- alt_path
}

if (file.exists(mod_primary_path) && file.exists(mod_no_int_path)) {
  mod_primary <- readRDS(mod_primary_path)
  mod_no_int <- readRDS(mod_no_int_path)
  
  aic_primary <- AIC(mod_primary)
  aic_no_int <- AIC(mod_no_int)
  delta_aic <- aic_primary - aic_no_int
  
  model_comparison <- tibble(
    Model = c("With Interaction", "Without Interaction"),
    AIC = c(aic_primary, aic_no_int),
    `ΔAIC` = c(delta_aic, NA)
  )
  
  # Return table directly (like Table 6) - don't use print()
  model_comparison %>%
    make_table(
      col.names = c("Model", "AIC", "ΔAIC"),
      digits = 2
    )
} else {
  cat("*Model comparison results not yet available.*")
  if (!file.exists(mod_primary_path)) {
    cat("\n  Primary model file not found:", mod_primary_path)
  }
  if (!file.exists(mod_no_int_path)) {
    cat("\n  No-interaction model file not found:", mod_no_int_path)
  }
}
```

```{r model-comparison-interpretation}
#| echo: false
#| results: 'asis'

# Compute interpretation based on AIC comparison
mod_primary_path <- file.path(models_dir, "mod_pupil_psychometric_primary.rds")
mod_no_int_path <- file.path(models_dir, "mod_pupil_psychometric_no_interaction.rds")

if (!file.exists(mod_primary_path)) {
  alt_path <- file.path(proj_root, "06_visualization", "output", "models", "mod_pupil_psychometric_primary.rds")
  if (file.exists(alt_path)) mod_primary_path <- alt_path
}
if (!file.exists(mod_no_int_path)) {
  alt_path <- file.path(proj_root, "06_visualization", "output", "models", "mod_pupil_psychometric_no_interaction.rds")
  if (file.exists(alt_path)) mod_no_int_path <- alt_path
}

if (file.exists(mod_primary_path) && file.exists(mod_no_int_path)) {
  mod_primary <- readRDS(mod_primary_path)
  mod_no_int <- readRDS(mod_no_int_path)
  aic_primary <- AIC(mod_primary)
  aic_no_int <- AIC(mod_no_int)
  delta_aic <- aic_primary - aic_no_int
  
  cat("**Interpretation:** ")
  if (delta_aic < -2) {
    cat("The model with the interaction term shows substantially better fit (ΔAIC < -2), supporting the inclusion of the interaction and the interpretation that pupil state modulates psychometric sensitivity.")
  } else if (delta_aic < 0) {
    cat("The model with the interaction term shows slightly better fit, though the difference is modest.")
  } else {
    cat("The model without the interaction term shows better fit, suggesting the interaction may not meaningfully improve model fit.")
  }
}
```

**3. Missingness Diagnostic**

As reported in the Missingness Diagnostic section above, we tested whether missing pupil data were systematically related to experimental conditions (effort, stimulus intensity, task, response time). If missingness is random or only related to non-experimental variables (e.g., individual differences in eye-tracking quality), this supports the validity of the primary analyses. If missingness is systematically related to experimental conditions, this could introduce bias and should be acknowledged in interpretation, with robustness checks helping to evaluate whether findings are sensitive to missingness patterns.

## Subject-Level PF–Pupil Coupling

```{r subject-coupling}
#| label: tbl-pf-pupil-correlations
#| tbl-cap: "Subject-Level Correlations: ΔPupil vs ΔPF Parameters"

if (!is.null(pf_pupil_correlations)) {
  pf_pupil_correlations %>%
    make_table(
      col.names = c("Pupil Metric", "PF Parameter", "r", "CI Lower", "CI Upper", "p", "N"),
      digits = 3
    )
} else {
  cat("*Subject-level coupling results not yet available.*")
}
```

Subject-level changes in pupil metrics (High–Low effort) were correlated with subject-level changes in PF parameters (High–Low effort). This analysis tests whether individuals who show stronger physiological responses to effort also show larger behavioral sensitivity changes.

**Hypothesis Testing:** Hypothesis 4 predicted that subject-level changes in pupil metrics (Δpupil = High effort − Low effort) would be positively correlated with changes in thresholds (Δthreshold) and negatively correlated with changes in slopes (Δslope), indicating that individuals with stronger effort-evoked arousal responses also show larger behavioral sensitivity decrements. This hypothesis was tested using Pearson correlations between Δpupil and ΔPF parameters, separately for each task modality.

```{r subject-coupling-fig}
#| label: fig-subject-coupling
#| fig-cap: "Subject-Level PF–Pupil Coupling"
#| fig-width: 12
#| fig-height: 6
#| out-width: "100%"

fig_path_abs1 <- fig_path("pf_pupil_coupling_threshold.png", return_absolute = TRUE)
fig_path_abs2 <- fig_path("pf_pupil_coupling_slope.png", return_absolute = TRUE)

# Display both figures
# Note: Each figure contains subplots for ADT and VDT conditions
if (!is.null(fig_path_abs1) && file.exists(fig_path_abs1) && 
    !is.null(fig_path_abs2) && file.exists(fig_path_abs2)) {
  # Display threshold figure
  fig_rel1 <- fig_path("pf_pupil_coupling_threshold.png")
  if (file.exists(fig_rel1)) {
    knitr::include_graphics(fig_rel1)
  } else {
    knitr::include_graphics(fig_path_abs1)
  }
  
  cat("\n\n")
  
  # Display slope figure
  fig_rel2 <- fig_path("pf_pupil_coupling_slope.png")
  if (file.exists(fig_rel2)) {
    knitr::include_graphics(fig_rel2)
  } else {
    knitr::include_graphics(fig_path_abs2)
  }
} else {
  cat("*Subject-level coupling figures not yet generated.*")
  if (is.null(fig_path_abs1) || !file.exists(fig_path_abs1)) {
    cat("\n  - Threshold figure missing")
  }
  if (is.null(fig_path_abs2) || !file.exists(fig_path_abs2)) {
    cat("\n  - Slope figure missing")
  }
}
```

```{r subject-coupling-matrix}
#| label: fig-subject-coupling-matrix
#| fig-cap: "Correlation Matrix: Subject-Level Changes"
#| fig-width: 10
#| fig-height: 10
#| out-width: "100%"

fig_path_abs <- fig_path("pf_pupil_coupling_matrix.png", return_absolute = TRUE)
if (!is.null(fig_path_abs) && file.exists(fig_path_abs)) {
  knitr::include_graphics(fig_path("pf_pupil_coupling_matrix.png"))
} else {
  cat("*Correlation matrix figure not yet generated.*")
}
```

## Exploratory LC Integrity Analyses

```{r lc-subset-bias}
#| label: tbl-lc-subset-bias
#| tbl-cap: "LC Integrity Subset: Comparison of Participants With vs. Without LC Data"

# Try to compute comparison if data available
# First check if pre-computed table exists
if (!is.null(lc_subset_comparison)) {
  tbl <- lc_subset_comparison %>%
    make_table(
      col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
      digits = 3
    )
  print(tbl)
} else if (!is.null(merged_data)) {
  # Compute from available data (even if LC integrity is incomplete)
  # Compute subset comparison if data available
  # Determine which subjects have LC data
  if (!is.null(lc_integrity) && nrow(lc_integrity) > 0 && "sub" %in% names(lc_integrity)) {
    subjects_with_lc <- unique(lc_integrity$sub[!is.na(lc_integrity$sub)])
  } else {
    # If no LC integrity file, check if we can identify subjects from other sources
    # For now, set to empty - table will show all subjects as "without LC data"
    subjects_with_lc <- character(0)
  }
  
  merged_data <- merged_data %>%
    mutate(has_lc_data = sub %in% subjects_with_lc)
  
  # Merge demographics if available
  if (!is.null(demographics) && nrow(demographics) > 0) {
    # Try to find subject ID column
    sub_col <- NULL
    if ("sub" %in% names(demographics)) {
      sub_col <- "sub"
    } else if ("subject_id" %in% names(demographics)) {
      demographics$sub <- demographics$subject_id
      sub_col <- "sub"
    } else if ("BAP" %in% names(demographics)) {
      demographics$sub <- demographics$BAP
      sub_col <- "sub"
    }
    
    if (!is.null(sub_col)) {
      # Find age, sex, education columns (may have different names)
      demo_cols <- c("sub")
      if ("age" %in% names(demographics) || "Age" %in% names(demographics)) {
        age_col <- ifelse("age" %in% names(demographics), "age", "Age")
        demographics$age <- as.numeric(demographics[[age_col]])
        demo_cols <- c(demo_cols, "age")
      }
      if ("sex" %in% names(demographics) || "Sex" %in% names(demographics)) {
        sex_col <- ifelse("sex" %in% names(demographics), "sex", "Sex")
        demographics$sex <- demographics[[sex_col]]
        demo_cols <- c(demo_cols, "sex")
      }
      if ("education" %in% names(demographics) || "Education" %in% names(demographics)) {
        edu_col <- ifelse("education" %in% names(demographics), "education", "Education")
        demographics$education <- as.numeric(demographics[[edu_col]])
        demo_cols <- c(demo_cols, "education")
      }
      
      merged_data <- merged_data %>%
        left_join(demographics %>% select(all_of(demo_cols)), by = "sub")
    }
  }
  
  # Compare groups
  # Build summarise call with only columns that exist
  subset_comparison <- merged_data %>%
    group_by(sub) %>%
    summarise(
      has_lc = first(has_lc_data),
      mean_accuracy = mean(correct_final, na.rm = TRUE),
      mean_rt = mean(rt, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Add demographics columns if they exist in merged_data
  if ("age" %in% names(merged_data)) {
    age_by_sub <- merged_data %>%
      group_by(sub) %>%
      summarise(age = first(age), .groups = "drop")
    subset_comparison <- subset_comparison %>%
      left_join(age_by_sub, by = "sub")
  }
  
  if ("sex" %in% names(merged_data)) {
    sex_by_sub <- merged_data %>%
      group_by(sub) %>%
      summarise(sex = first(sex), .groups = "drop")
    subset_comparison <- subset_comparison %>%
      left_join(sex_by_sub, by = "sub")
  }
  
  if ("education" %in% names(merged_data)) {
    edu_by_sub <- merged_data %>%
      group_by(sub) %>%
      summarise(education = first(education), .groups = "drop")
    subset_comparison <- subset_comparison %>%
      left_join(edu_by_sub, by = "sub")
  }
  
  # Filter out rows where has_lc is NA
  subset_comparison <- subset_comparison %>%
    filter(!is.na(has_lc))
  
  # Create comparison even if no LC data yet (will show all as "without LC data")
  # This allows the table structure to be visible
  if (nrow(subset_comparison) > 0) {
    # Check if we have any subjects with LC data
    has_lc_subjects <- sum(subset_comparison$has_lc, na.rm = TRUE) > 0
    has_no_lc_subjects <- sum(!subset_comparison$has_lc, na.rm = TRUE) > 0
    
    if (has_lc_subjects && has_no_lc_subjects) {
    # Statistical tests
    comparison_results <- tibble(
      Variable = character(),
      `With LC Data` = character(),
      `Without LC Data` = character(),
      `Test Statistic` = character(),
      p = numeric()
    )
    
    # Age comparison
    if ("age" %in% names(subset_comparison) && sum(!is.na(subset_comparison$age)) > 0) {
      age_test <- t.test(age ~ has_lc, data = subset_comparison)
      comparison_results <- comparison_results %>%
        add_row(
          Variable = "Age (years)",
          `With LC Data` = sprintf("%.1f (%.1f)", 
                                   mean(subset_comparison$age[subset_comparison$has_lc], na.rm = TRUE),
                                   sd(subset_comparison$age[subset_comparison$has_lc], na.rm = TRUE)),
          `Without LC Data` = sprintf("%.1f (%.1f)", 
                                     mean(subset_comparison$age[!subset_comparison$has_lc], na.rm = TRUE),
                                     sd(subset_comparison$age[!subset_comparison$has_lc], na.rm = TRUE)),
          `Test Statistic` = sprintf("t = %.2f", age_test$statistic),
          p = age_test$p.value
        )
    }
    
    # Sex comparison
    if ("sex" %in% names(subset_comparison)) {
      sex_table <- table(subset_comparison$has_lc, subset_comparison$sex)
      if (ncol(sex_table) > 0 && nrow(sex_table) > 0) {
        sex_test <- chisq.test(sex_table)
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Sex (M/F)",
            `With LC Data` = paste(sex_table[2,], collapse = "/"),
            `Without LC Data` = paste(sex_table[1,], collapse = "/"),
            `Test Statistic` = sprintf("χ² = %.2f", sex_test$statistic),
            p = sex_test$p.value
          )
      }
    }
    
    # Education comparison
    if ("education" %in% names(subset_comparison) && sum(!is.na(subset_comparison$education)) > 0) {
      edu_test <- t.test(education ~ has_lc, data = subset_comparison)
      comparison_results <- comparison_results %>%
        add_row(
          Variable = "Education (years)",
          `With LC Data` = sprintf("%.1f (%.1f)", 
                                  mean(subset_comparison$education[subset_comparison$has_lc], na.rm = TRUE),
                                  sd(subset_comparison$education[subset_comparison$has_lc], na.rm = TRUE)),
          `Without LC Data` = sprintf("%.1f (%.1f)", 
                                     mean(subset_comparison$education[!subset_comparison$has_lc], na.rm = TRUE),
                                     sd(subset_comparison$education[!subset_comparison$has_lc], na.rm = TRUE)),
          `Test Statistic` = sprintf("t = %.2f", edu_test$statistic),
          p = edu_test$p.value
        )
    }
    
    if (nrow(comparison_results) > 0) {
      # Return table (will be rendered by Quarto)
      comparison_results %>%
        make_table(
          col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
          digits = 3
        )
    } else {
      # Create empty table structure
      empty_tbl <- tibble(
        Variable = "No comparison results computed",
        `With LC Data` = NA_character_,
        `Without LC Data` = NA_character_,
        `Test Statistic` = NA_character_,
        p = NA_real_
      )
      empty_tbl %>%
        make_table(
          col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
          digits = 3
        )
    }
  } else {
    # No LC data available yet - show table structure with all subjects as "without LC data"
      # This provides the table structure even when LC data is incomplete
      comparison_results <- tibble(
        Variable = character(),
        `With LC Data` = character(),
        `Without LC Data` = character(),
        `Test Statistic` = character(),
        p = numeric()
      )
      
      # Age comparison (all subjects in "without LC" group for now)
      if ("age" %in% names(subset_comparison) && sum(!is.na(subset_comparison$age)) > 0) {
        age_mean <- mean(subset_comparison$age, na.rm = TRUE)
        age_sd <- sd(subset_comparison$age, na.rm = TRUE)
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Age (years)",
            `With LC Data` = "N/A",
            `Without LC Data` = sprintf("%.1f (%.1f)", age_mean, age_sd),
            `Test Statistic` = "N/A",
            p = NA_real_
          )
      }
      
      # Sex comparison
      if ("sex" %in% names(subset_comparison)) {
        sex_counts <- table(subset_comparison$sex, useNA = "ifany")
        sex_str <- paste(sex_counts, collapse = "/")
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Sex (M/F)",
            `With LC Data` = "N/A",
            `Without LC Data` = sex_str,
            `Test Statistic` = "N/A",
            p = NA_real_
          )
      }
      
      # Education comparison
      if ("education" %in% names(subset_comparison) && sum(!is.na(subset_comparison$education)) > 0) {
        edu_mean <- mean(subset_comparison$education, na.rm = TRUE)
        edu_sd <- sd(subset_comparison$education, na.rm = TRUE)
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Education (years)",
            `With LC Data` = "N/A",
            `Without LC Data` = sprintf("%.1f (%.1f)", edu_mean, edu_sd),
            `Test Statistic` = "N/A",
            p = NA_real_
          )
      }
      
      # Behavioral measures
      if ("mean_accuracy" %in% names(subset_comparison) && sum(!is.na(subset_comparison$mean_accuracy)) > 0) {
        acc_mean <- mean(subset_comparison$mean_accuracy, na.rm = TRUE)
        acc_sd <- sd(subset_comparison$mean_accuracy, na.rm = TRUE)
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Mean Accuracy",
            `With LC Data` = "N/A",
            `Without LC Data` = sprintf("%.3f (%.3f)", acc_mean, acc_sd),
            `Test Statistic` = "N/A",
            p = NA_real_
          )
      }
      
      if ("mean_rt" %in% names(subset_comparison) && sum(!is.na(subset_comparison$mean_rt)) > 0) {
        rt_mean <- mean(subset_comparison$mean_rt, na.rm = TRUE)
        rt_sd <- sd(subset_comparison$mean_rt, na.rm = TRUE)
        comparison_results <- comparison_results %>%
          add_row(
            Variable = "Mean RT (ms)",
            `With LC Data` = "N/A",
            `Without LC Data` = sprintf("%.1f (%.1f)", rt_mean, rt_sd),
            `Test Statistic` = "N/A",
            p = NA_real_
          )
      }
      
      if (nrow(comparison_results) > 0) {
        # Return table (will be rendered by Quarto)
        comparison_results %>%
          make_table(
            col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
            digits = 3
          )
      } else {
        # Create empty table structure
        empty_tbl <- tibble(
          Variable = "Insufficient data for comparison",
          `With LC Data` = NA_character_,
          `Without LC Data` = NA_character_,
          `Test Statistic` = NA_character_,
          p = NA_real_
        )
        empty_tbl %>%
          make_table(
            col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
            digits = 3
          )
      }
    }
  } else {
    # Create empty table structure
    empty_tbl <- tibble(
      Variable = "Insufficient data for comparison",
      `With LC Data` = NA_character_,
      `Without LC Data` = NA_character_,
      `Test Statistic` = NA_character_,
      p = NA_real_
    )
    empty_tbl %>%
      make_table(
        col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
        digits = 3
      )
  }
} else {
  # Create empty table structure
  empty_tbl <- tibble(
    Variable = "LC subset comparison not yet available. Merged data not available.",
    `With LC Data` = NA_character_,
    `Without LC Data` = NA_character_,
    `Test Statistic` = NA_character_,
    p = NA_real_
  )
  empty_tbl %>%
    make_table(
      col.names = c("Variable", "With LC Data", "Without LC Data", "Test Statistic", "p"),
      digits = 3
    )
}
```

**LC Integrity as Moderator of Pupil–Psychometric Coupling**

```{r lc-psychometric-extension}
#| label: tbl-lc-psychometric-extension
#| tbl-cap: "Exploratory LC Integrity Extension: Three-Way Interaction"

if (!is.null(lc_psychometric_effects)) {
  # Return table (will be rendered by Quarto)
  lc_psychometric_effects %>%
    filter(term %in% c("stimulus_intensity_scaled:pupil_cognitive_state_scaled",
                       "stimulus_intensity_scaled:pupil_cognitive_state_scaled:lc_integrity_scaled",
                       "lc_integrity_scaled")) %>%
    select(term, estimate, std.error, statistic, p.value) %>%
    mutate(
      term = str_replace_all(term, c(
        "stimulus_intensity_scaled:pupil_cognitive_state_scaled" = "Stimulus × Pupil State",
        "stimulus_intensity_scaled:pupil_cognitive_state_scaled:lc_integrity_scaled" = "Stimulus × Pupil State × LC Integrity",
        "lc_integrity_scaled" = "LC Integrity (main effect)"
      ))
    ) %>%
    make_table(
      col.names = c("Term", "Estimate", "SE", "z", "p"),
      digits = 4
    )
} else {
  # Create a placeholder table so the caption and numbering render consistently
  status_tbl <- tibble(
    Term = "Status: Analysis pending",
    Estimate = NA_real_,
    SE = NA_real_,
    z = NA_real_,
    p = NA_real_
  )
  
  # Return table (will be rendered by Quarto)
  status_tbl %>%
    make_table(
      col.names = c("Term", "Estimate", "SE", "z", "p"),
      digits = 4
    )
}
```

```{r lc-psychometric-extension-note, echo=FALSE, results='asis'}
# Add note after table
if (!is.null(lc_psychometric_effects)) {
  cat("\n\n**Note:** These analyses are exploratory and should be interpreted with caution given that (a) LC integrity data were not part of the original prospectus, (b) LC data are available for only a subset of participants, and (c) the primary focus remains on pupil–psychometric coupling rather than LC integrity per se.")
} else {
  cat("\n\n**Note:** ⚠️ **INCOMPLETE ANALYSIS** — LC integrity extension models have not yet been fit because LC integrity data are still being added to the master spreadsheet for some participants (BAP 191–202, excluding 193 and 198). ")
  cat("Once LC integrity scores are available in `data/processed/ch2_lc_integrity.csv` and the script `04_pupil_psychometric_coupling/06b_lc_integrity_extension.R` has been run, this table will be updated with three-way interaction results (Stimulus × Pupil State × LC Integrity).")
}
```

## Summary of Hypothesis Testing

```{r hypothesis-summary}
#| label: tbl-hypothesis-summary
#| tbl-cap: "Summary of Hypothesis Testing Results"

# Load results for evaluation
pf_threshold_effort <- sread(file.path(tables_dir, "pf_threshold_effort_effects.csv"))
pf_slope_effort <- sread(file.path(tables_dir, "pf_slope_effort_effects.csv"))

# Evaluate H1a: Thresholds higher under High effort
h1a_status <- "Analysis pending"
h1a_evidence <- "PF threshold comparison (High vs Low effort)"
if (!is.null(pf_threshold_effort)) {
  effort_effect <- pf_threshold_effort %>%
    filter(term == "effort_factorHigh")
  if (nrow(effort_effect) > 0) {
    # Check if p.value exists, otherwise use t-statistic
    if ("p.value" %in% names(effort_effect) && !is.na(effort_effect$p.value)) {
      if (effort_effect$p.value < 0.05 && effort_effect$estimate > 0) {
        h1a_status <- sprintf("Supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      } else if (effort_effect$p.value < 0.05 && effort_effect$estimate < 0) {
        h1a_status <- sprintf("Not supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      } else {
        h1a_status <- sprintf("Not supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      }
      h1a_evidence <- sprintf("Threshold: High vs Low effort (β=%.3f, p=%.3f)", 
                             effort_effect$estimate, effort_effect$p.value)
    } else if ("statistic" %in% names(effort_effect) && !is.na(effort_effect$statistic)) {
      # Fallback: use t-statistic (|t| > 2 is approximately p < 0.05)
      if (abs(effort_effect$statistic) > 2 && effort_effect$estimate > 0) {
        h1a_status <- sprintf("Supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      } else if (abs(effort_effect$statistic) > 2 && effort_effect$estimate < 0) {
        h1a_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      } else {
        h1a_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      }
      h1a_evidence <- sprintf("Threshold: High vs Low effort (β=%.3f, t=%.2f)", 
                             effort_effect$estimate, effort_effect$statistic)
    }
  }
}

# Evaluate H1b: Slopes shallower under High effort
h1b_status <- "Analysis pending"
h1b_evidence <- "PF slope comparison (High vs Low effort)"
if (!is.null(pf_slope_effort)) {
  effort_effect <- pf_slope_effort %>%
    filter(term == "effort_factorHigh")
  if (nrow(effort_effect) > 0) {
    # Check if p.value exists, otherwise use t-statistic
    if ("p.value" %in% names(effort_effect) && !is.na(effort_effect$p.value)) {
      if (effort_effect$p.value < 0.05 && effort_effect$estimate < 0) {
        h1b_status <- sprintf("Supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      } else if (effort_effect$p.value < 0.05 && effort_effect$estimate > 0) {
        h1b_status <- sprintf("Not supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      } else {
        h1b_status <- sprintf("Not supported (β=%.3f, p=%.3f)", effort_effect$estimate, effort_effect$p.value)
      }
      h1b_evidence <- sprintf("Slope: High vs Low effort (β=%.3f, p=%.3f)", 
                            effort_effect$estimate, effort_effect$p.value)
    } else if ("statistic" %in% names(effort_effect) && !is.na(effort_effect$statistic)) {
      # Fallback: use t-statistic (|t| > 2 is approximately p < 0.05)
      if (abs(effort_effect$statistic) > 2 && effort_effect$estimate < 0) {
        h1b_status <- sprintf("Supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      } else if (abs(effort_effect$statistic) > 2 && effort_effect$estimate > 0) {
        h1b_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      } else {
        h1b_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
      }
      h1b_evidence <- sprintf("Slope: High vs Low effort (β=%.3f, t=%.2f)", 
                            effort_effect$estimate, effort_effect$statistic)
    }
  }
}

# Evaluate H2a: Baseline pupil larger under High effort (Total AUC)
h2a_status <- "To be evaluated"
h2a_evidence <- "Total AUC by effort"
if (!is.null(effort_total_auc_effects)) {
  effort_effect <- effort_total_auc_effects %>%
    filter(term == "effort_factorHigh")
  if (nrow(effort_effect) > 0) {
    # Note: t-value indicates significance (|t| > 2 typically significant)
    if (abs(effort_effect$statistic) > 2 && effort_effect$estimate > 0) {
      h2a_status <- sprintf("Supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
    } else if (abs(effort_effect$statistic) > 2 && effort_effect$estimate < 0) {
      h2a_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
    } else {
      h2a_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
    }
    h2a_evidence <- sprintf("Total AUC: High vs Low effort (β=%.3f, t=%.2f)", 
                           effort_effect$estimate, effort_effect$statistic)
  }
}

# Evaluate H2b: Task-evoked pupil larger under High effort (Cognitive AUC)
h2b_status <- "To be evaluated"
h2b_evidence <- "Cognitive AUC by effort"
if (!is.null(effort_pupil_effects)) {
  effort_effect <- effort_pupil_effects %>%
    filter(term == "effort_factorHigh")
  if (nrow(effort_effect) > 0) {
    # Note: Cognitive AUC shows negative effect - needs investigation
    if (abs(effort_effect$statistic) > 2 && effort_effect$estimate > 0) {
      h2b_status <- sprintf("Supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
    } else if (abs(effort_effect$statistic) > 2 && effort_effect$estimate < 0) {
      h2b_status <- sprintf("Not supported (β=%.3f, t=%.2f) - Note: Unexpected direction", 
                           effort_effect$estimate, effort_effect$statistic)
    } else {
      h2b_status <- sprintf("Not supported (β=%.3f, t=%.2f)", effort_effect$estimate, effort_effect$statistic)
    }
    h2b_evidence <- sprintf("Cognitive AUC: High vs Low effort (β=%.3f, t=%.2f)", 
                           effort_effect$estimate, effort_effect$statistic)
  }
}

# Evaluate H3a: Negative interaction (stimulus × pupil state)
h3a_status <- "Not supported"
h3a_evidence <- "Interaction term: stimulus_intensity × pupil_state"
if (!is.null(pupil_psychometric_effects)) {
  interaction_effect <- pupil_psychometric_effects %>%
    filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
  if (nrow(interaction_effect) > 0 && "p.value" %in% names(interaction_effect)) {
    if (interaction_effect$p.value < 0.05 && interaction_effect$estimate < 0) {
      h3a_status <- sprintf("Supported (β=%.3f, p=%.3f)", interaction_effect$estimate, interaction_effect$p.value)
    } else {
      h3a_status <- sprintf("Not supported (β=%.3f, p=%.3f)", interaction_effect$estimate, interaction_effect$p.value)
    }
    h3a_evidence <- sprintf("Interaction: stimulus × pupil state (β=%.3f, z=%.2f, p=%.3f)", 
                           interaction_effect$estimate, interaction_effect$statistic, interaction_effect$p.value)
  }
}

# Evaluate H3b: Positive interaction (alternative)
h3b_status <- "Not supported"
h3b_evidence <- "Interaction term: stimulus_intensity × pupil_state"
if (!is.null(pupil_psychometric_effects)) {
  interaction_effect <- pupil_psychometric_effects %>%
    filter(term == "stimulus_intensity_scaled:pupil_cognitive_state_scaled")
  if (nrow(interaction_effect) > 0 && "p.value" %in% names(interaction_effect)) {
    if (interaction_effect$p.value < 0.05 && interaction_effect$estimate > 0) {
      h3b_status <- sprintf("Supported (β=%.3f, p=%.3f)", interaction_effect$estimate, interaction_effect$p.value)
    } else {
      h3b_status <- sprintf("Not supported (β=%.3f, p=%.3f)", interaction_effect$estimate, interaction_effect$p.value)
    }
    h3b_evidence <- sprintf("Interaction: stimulus × pupil state (β=%.3f, z=%.2f, p=%.3f)", 
                           interaction_effect$estimate, interaction_effect$statistic, interaction_effect$p.value)
  }
}

# Evaluate H3c: Minimal pupil trait effects
h3c_status <- "Supported"
h3c_evidence <- "Pupil trait main effect"
if (!is.null(pupil_psychometric_effects)) {
  trait_effect <- pupil_psychometric_effects %>%
    filter(term == "pupil_cognitive_trait_scaled")
  if (nrow(trait_effect) > 0 && "p.value" %in% names(trait_effect)) {
    if (trait_effect$p.value > 0.05) {
      h3c_status <- sprintf("Supported (β=%.3f, p=%.3f)", trait_effect$estimate, trait_effect$p.value)
    } else {
      h3c_status <- sprintf("Not supported (β=%.3f, p=%.3f)", trait_effect$estimate, trait_effect$p.value)
    }
    h3c_evidence <- sprintf("Pupil trait effect (β=%.3f, z=%.2f, p=%.3f)", 
                           trait_effect$estimate, trait_effect$statistic, trait_effect$p.value)
  }
}

# Evaluate H4: ΔPupil correlated with ΔPF parameters
h4_status <- "Partially supported"
h4_evidence <- "Correlation: Δpupil vs Δthreshold, Δslope"
if (!is.null(pf_pupil_correlations)) {
  # Check threshold correlations
  threshold_cog <- pf_pupil_correlations %>%
    filter(pupil_metric == "Cognitive AUC", pf_parameter == "Threshold")
  threshold_total <- pf_pupil_correlations %>%
    filter(pupil_metric == "Total AUC", pf_parameter == "Threshold")
  slope_cog <- pf_pupil_correlations %>%
    filter(pupil_metric == "Cognitive AUC", pf_parameter == "Slope")
  slope_total <- pf_pupil_correlations %>%
    filter(pupil_metric == "Total AUC", pf_parameter == "Slope")
  
  sig_correlations <- pf_pupil_correlations %>%
    filter(p_value < 0.05)
  
  if (nrow(sig_correlations) > 0) {
    h4_status <- sprintf("Partially supported (%d/%d correlations significant)", 
                        nrow(sig_correlations), nrow(pf_pupil_correlations))
  } else {
    h4_status <- "Not supported (no significant correlations)"
  }
  
  h4_evidence <- sprintf("Correlations: ΔCog-Threshold r=%.2f (p=%.3f), ΔCog-Slope r=%.2f (p=%.3f)", 
                        threshold_cog$correlation[1], threshold_cog$p_value[1],
                        slope_cog$correlation[1], slope_cog$p_value[1])
}

# Create hypothesis summary table
hypothesis_summary <- tibble(
  Hypothesis = c(
    "H1a: Thresholds higher under High effort",
    "H1b: Slopes shallower under High effort",
    "H2a: Baseline pupil larger under High effort",
    "H2b: Task-evoked pupil larger under High effort",
    "H3a: Negative interaction (stimulus × pupil state)",
    "H3b: Positive interaction (alternative)",
    "H3c: Minimal pupil trait effects",
    "H4: ΔPupil correlated with ΔPF parameters"
  ),
  `Support Status` = c(
    h1a_status,
    h1b_status,
    h2a_status,
    h2b_status,
    h3a_status,
    h3b_status,
    h3c_status,
    h4_status
  ),
  `Key Evidence` = c(
    h1a_evidence,
    h1b_evidence,
    h2a_evidence,
    h2b_evidence,
    h3a_evidence,
    h3b_evidence,
    h3c_evidence,
    h4_evidence
  )
)

hypothesis_summary %>%
  make_table(
    col.names = c("Hypothesis", "Support Status", "Key Evidence"),
    digits = 3
  )

cat("\n**Note:** H1a and H1b require running `01_data_preparation/03_test_pf_parameters_effort.R` to generate statistical tests. H2b shows an unexpected negative effect that needs investigation.")
```

# Discussion

## Integration with Theoretical Frameworks

The present findings contribute to understanding how physical effort and arousal relate to perceptual sensitivity in older adults. The results are interpreted in light of several theoretical frameworks introduced earlier: the Yerkes–Dodson law (inverted-U relationship between arousal and performance), Adaptive Gain Theory (optimal LC–NE balance for performance), and resource competition models (limited capacity for dual-task performance).

### Arousal–Performance Relationships

If the primary interaction (stimulus intensity × pupil state) is significant and negative, this would support the hypothesis that higher trial-level arousal is associated with reduced psychometric sensitivity, consistent with supra-optimal arousal degrading signal quality in older adults. This pattern would align with the Yerkes–Dodson framework's prediction that older adults may be more easily pushed onto the descending limb of the arousal–performance curve [@mather2016; @huang2024]. Alternatively, if the interaction is non-significant, this suggests that moment-to-moment arousal fluctuations may not be the primary mechanism linking effort to sensitivity changes. In this case, effort main effects (which may reflect both resource competition and group-level arousal changes) may be the dominant drivers of performance differences.

### Resource Competition vs. Arousal Mechanisms

The chapter's focus on pupil-indexed arousal does not preclude resource competition as a contributing mechanism. Effort main effects in the GLMM capture overall High vs. Low effort differences, which may reflect both generic dual-task interference and arousal-mediated changes. If trial-wise pupil state does not significantly predict sensitivity beyond effort condition, this would suggest that resource competition or effort-induced group-level arousal changes (rather than moment-to-moment fluctuations) are the primary drivers. The psychometric function framework allows us to distinguish sensitivity changes (signal quality) from criterion shifts (response strategy), providing insight into whether effort effects reflect altered evidence quality (consistent with arousal effects on neural gain) versus strategic adjustments (consistent with resource allocation).

### State vs. Trait Arousal Effects

The decomposition of pupil metrics into state (within-person) and trait (between-person) components allows us to test distinct hypotheses about how arousal relates to sensitivity. If pupil state significantly predicts sensitivity (via the interaction), this supports the hypothesis that moment-to-moment arousal fluctuations modulate perceptual processing. If pupil trait shows minimal effects (as predicted by Hypothesis 3c), this suggests that stable individual differences in average arousal may be confounded with other factors (e.g., LC integrity, cognitive reserve, general health) that are better captured by direct measures of those constructs.

## Implications for Aging and Arousal

The findings have implications for understanding how aging modulates the relationship between physiological arousal and cognitive performance. If older adults show weaker or absent coupling between trial-wise arousal and sensitivity (compared to younger adults in Chapter 1), this could indicate age-related changes in how the LC–NE system modulates cortical gain. Alternatively, if effort main effects are robust but trial-wise coupling is weak, this suggests that older adults may be more sensitive to effort-induced arousal at the group level but less sensitive to moment-to-moment fluctuations, potentially reflecting reduced phasic LC responsiveness or altered gain modulation.

## Limitations

Several limitations should be considered when interpreting the findings:

### Pupil Data Quality Constraints

Pupil data quality varies across older adults due to factors such as eye-tracking challenges, increased blink rates, and age-related changes in pupil dynamics. The quality tier system (primary ≥0.60, lenient ≥0.50, strict ≥0.70) addresses this by testing robustness across different inclusion criteria. However, even with quality filtering, some participants may have limited usable pupil data, potentially reducing power for detecting state-level effects.

### Missingness Patterns

The missingness diagnostic tests whether pupil data loss is systematic (e.g., related to effort, stimulus intensity, or task). If missingness is predicted by experimental conditions, this could introduce bias. The robustness checks across quality tiers help evaluate whether findings are sensitive to missingness patterns, but systematic missingness remains a potential limitation.

### Sample Size Considerations

The effective sample size for detecting trial-level interactions depends on both the number of participants and the number of usable trials per participant. If many participants have sparse pupil data, power to detect state-level effects may be limited. The model comparison (AIC) and robustness checks help evaluate whether null findings reflect true absence of effects versus insufficient power.

### LC Integrity Subset Limitations

LC integrity data are available for only a subset of participants. If participants with LC data differ systematically from those without (e.g., in age, cognitive function, or behavioral performance), this limits the generalizability of LC integrity findings. The LC subset bias check addresses this, but the exploratory LC analyses should be interpreted with caution given the subset limitation.

### Fixed-Window vs. Response-Locked Metrics

The primary cognitive pupil metric uses a fixed-duration post-target window to reduce RT confounding. However, this may not capture the most relevant arousal dynamics for psychometric sensitivity. Response-locked metrics (evaluated in sensitivity analyses) may better capture decision-related arousal but are more susceptible to RT confounding. The choice of window definition represents a trade-off between physiological validity and measurement confounds.

## Integration with Chapter 1 and Chapter 3

Chapter 2 extends the dual-task paradigm from younger adults (Chapter 1) to older adults, testing whether arousal–sensitivity coupling is preserved or altered with age. If Chapter 1 shows robust coupling in younger adults but Chapter 2 shows weaker or absent coupling in older adults, this would suggest age-related changes in how arousal modulates perceptual sensitivity. Alternatively, if both chapters show similar patterns, this would suggest that the arousal–sensitivity relationship is relatively stable across the adult lifespan, with age effects manifesting primarily in baseline sensitivity or effort reactivity rather than in the coupling mechanism itself.

Chapter 3 will use hierarchical drift diffusion modeling to decompose the behavioral patterns observed in Chapter 2 into latent decision parameters (drift rate, boundary separation, starting point, non-decision time). This will test whether arousal effects are more consistent with altered evidence quality (drift rate changes) versus strategic response adjustments (boundary separation changes), providing a mechanistic account of how physical effort and arousal reshape perceptual decisions in aging.

## Conclusions and Future Directions

Chapter 2 provides a statistically rigorous characterization of how pupil-indexed arousal covaries with psychophysical decision behavior in older adults, using continuous stimulus intensity modeling and within-subject centering to preserve individual arousal granularity. The findings contribute to understanding whether physical effort–induced arousal modulates perceptual sensitivity at the trial level, and whether this relationship is robust across data quality thresholds and model specifications.

Future research directions include: (a) examining whether different pupil window definitions (e.g., response-locked, different durations) reveal stronger coupling, (b) testing whether LC integrity moderates arousal–sensitivity relationships, (c) comparing arousal–sensitivity coupling between younger and older adults directly, and (d) using computational modeling (Chapter 3) to identify the latent decision parameters that implement the observed behavioral patterns.

The work presented here establishes the empirical and methodological foundation for Chapter 3, which will examine whether latent decision parameters provide a coherent mechanistic account of how physical effort and arousal reshape perceptual decisions in aging.

# References

<!-- References will be automatically generated from references.bib -->

```{r}
#| include: false
# Bibliography will be rendered automatically from references.bib
```

